{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbrtsqKDNVbA"
      },
      "source": [
        "## Import Modules \n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwLwecBZNsyf"
      },
      "source": [
        "## Model Configuration (Initialize hyperparameters)\n",
        "batch_size = 64\n",
        "learning_rate = 0.01\n",
        "cross_entropy = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDRmYyWUtV-n"
      },
      "source": [
        "## DataLoader (Load the training set and validation set using Dataset and DataLoader)\n",
        "transform = torchvision.transforms.ToTensor()\n",
        "train_data = torch.utils.data.DataLoader(\n",
        "    torchvision.datasets.MNIST(\n",
        "    'mnist_data', train=True, download=True, transform=transform\n",
        "    ), batch_size=batch_size\n",
        ")\n",
        "val_data = torch.utils.data.DataLoader(\n",
        "    torchvision.datasets.MNIST(\n",
        "    'mnist_data', train=False, download=True, transform=transform\n",
        "    ), batch_size=batch_size\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ea9v0rBFtWAj"
      },
      "source": [
        "# Validation function (To check whether the model is learning properly we can use a validation set)\n",
        "def validate(model, data):\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for i, (images, labels) in enumerate(data):\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        y_pred = model(images)\n",
        "        value, pred = torch.max(y_pred, 1)\n",
        "        total += y_pred.size(0)\n",
        "        correct += torch.sum(pred == labels)\n",
        "    return correct * 100 / total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Uc9ybejtWCY"
      },
      "source": [
        "## Training Function (Training the model)\n",
        "def train(model,epochs=5) :\n",
        "    optimizer = optim.Adam(model.parameters(),lr=learning_rate)    \n",
        "    for n in range(epochs)  :\n",
        "        for i , (images , labels) in enumerate(train_data) :\n",
        "            images = images.cuda()\n",
        "            labels = labels.cuda()\n",
        "            optimizer.zero_grad()\n",
        "            prediction = model(images)\n",
        "            loss = cross_entropy(prediction, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        accuracy = float(validate(model, val_data))\n",
        "        print(\"Epoch:\", n+1, \"Loss: \", float(loss.data), \"Accuracy:\", accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90WCj3fbtWEb"
      },
      "source": [
        "## Model (A sample CNN is defined here for image classification)\n",
        "class CNNWithPool(nn.Module) :\n",
        "    def __init__(self):\n",
        "        super(CNNWithPool,self).__init__()\n",
        "        self.conv_1 = nn.Conv2d(in_channels=1,out_channels=16,kernel_size=3)\n",
        "        self.conv_2 = nn.Conv2d(in_channels=16,out_channels=32,kernel_size=3)\n",
        "        \n",
        "        self.pool_1 = nn.MaxPool2d(2)\n",
        "        self.pool_2 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.dense_1 = nn.Linear(in_features=800,out_features=256)\n",
        "        self.dense_2 = nn.Linear(in_features=256,out_features=10)\n",
        "\n",
        "        self.tanh = nn.Tanh()\n",
        "    def forward(self,x) :\n",
        "        x = self.tanh(self.conv_1(x))\n",
        "        x = self.pool_1(x)\n",
        "        x = self.tanh(self.conv_2(x))\n",
        "        x = self.pool_2(x)\n",
        "        x = x.view(x.shape[0],-1)\n",
        "        x = self.tanh(self.dense_1(x))\n",
        "        x = self.dense_2(x)\n",
        "        # output = self.tanh(x)\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYRgTkK2tWGi"
      },
      "source": [
        "# Model (Initialize the neural network)\n",
        "model = CNNWithPool().cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6jbvgbAtWJP",
        "outputId": "32389779-1e8d-449a-d1c1-036d799eda36"
      },
      "source": [
        "# Summary\n",
        "summary(model, (1, 28, 28))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 26, 26]             160\n",
            "              Tanh-2           [-1, 16, 26, 26]               0\n",
            "         MaxPool2d-3           [-1, 16, 13, 13]               0\n",
            "            Conv2d-4           [-1, 32, 11, 11]           4,640\n",
            "              Tanh-5           [-1, 32, 11, 11]               0\n",
            "         MaxPool2d-6             [-1, 32, 5, 5]               0\n",
            "            Linear-7                  [-1, 256]         205,056\n",
            "              Tanh-8                  [-1, 256]               0\n",
            "            Linear-9                   [-1, 10]           2,570\n",
            "================================================================\n",
            "Total params: 212,426\n",
            "Trainable params: 212,426\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.25\n",
            "Params size (MB): 0.81\n",
            "Estimated Total Size (MB): 1.07\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1lgF6e7uJFg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81e3e325-5a93-4975-a9d8-481a024663b0"
      },
      "source": [
        "# Train for 30 Epochs\n",
        "train(model,epochs=30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 Loss:  0.009247204288840294 Accuracy: 94.86000061035156\n",
            "Epoch: 2 Loss:  0.0018443128792569041 Accuracy: 95.08999633789062\n",
            "Epoch: 3 Loss:  0.2627520263195038 Accuracy: 95.13999938964844\n",
            "Epoch: 4 Loss:  0.0019994506146758795 Accuracy: 96.39999389648438\n",
            "Epoch: 5 Loss:  0.007705670315772295 Accuracy: 95.1199951171875\n",
            "Epoch: 6 Loss:  0.04874978959560394 Accuracy: 94.05999755859375\n",
            "Epoch: 7 Loss:  0.0525917112827301 Accuracy: 96.3499984741211\n",
            "Epoch: 8 Loss:  0.029023030772805214 Accuracy: 95.39999389648438\n",
            "Epoch: 9 Loss:  0.05686714127659798 Accuracy: 94.44999694824219\n",
            "Epoch: 10 Loss:  0.006317119114100933 Accuracy: 94.80999755859375\n",
            "Epoch: 11 Loss:  0.003050532890483737 Accuracy: 95.90999603271484\n",
            "Epoch: 12 Loss:  0.004467764403671026 Accuracy: 96.08999633789062\n",
            "Epoch: 13 Loss:  0.005192233249545097 Accuracy: 96.70999908447266\n",
            "Epoch: 14 Loss:  0.006924818269908428 Accuracy: 97.00999450683594\n",
            "Epoch: 15 Loss:  0.11356080323457718 Accuracy: 95.68000030517578\n",
            "Epoch: 16 Loss:  0.027163036167621613 Accuracy: 96.48999786376953\n",
            "Epoch: 17 Loss:  0.019562099128961563 Accuracy: 96.95999908447266\n",
            "Epoch: 18 Loss:  0.008698543533682823 Accuracy: 96.22000122070312\n",
            "Epoch: 19 Loss:  0.013477327302098274 Accuracy: 96.77999877929688\n",
            "Epoch: 20 Loss:  0.16850057244300842 Accuracy: 95.8499984741211\n",
            "Epoch: 21 Loss:  0.23440898954868317 Accuracy: 95.72000122070312\n",
            "Epoch: 22 Loss:  0.09931676834821701 Accuracy: 95.90999603271484\n",
            "Epoch: 23 Loss:  0.0004262481816112995 Accuracy: 97.13999938964844\n",
            "Epoch: 24 Loss:  0.1048838421702385 Accuracy: 95.95999908447266\n",
            "Epoch: 25 Loss:  0.06745371967554092 Accuracy: 95.14999389648438\n",
            "Epoch: 26 Loss:  0.001249469816684723 Accuracy: 96.56999969482422\n",
            "Epoch: 27 Loss:  0.1981784552335739 Accuracy: 96.72000122070312\n",
            "Epoch: 28 Loss:  0.0017126702005043626 Accuracy: 96.30999755859375\n",
            "Epoch: 29 Loss:  0.6451265811920166 Accuracy: 95.80999755859375\n",
            "Epoch: 30 Loss:  0.0033443842548877 Accuracy: 95.22000122070312\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUS-wn-vDamN"
      },
      "source": [
        "**We can see that by using pooling, the number of parameters has been reduced, resulting in quicker training times without sacrificing the quality of the findings**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvYvNqVmuJII"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}