{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q4",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbrtsqKDNVbA"
      },
      "source": [
        "## Import Modules \n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwLwecBZNsyf"
      },
      "source": [
        "## Model Configuration (Initialize hyperparameters)\n",
        "batch_size = 64\n",
        "learning_rate = 0.01\n",
        "cross_entropy = nn.CrossEntropyLoss()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDRmYyWUtV-n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e955b9ed-03c1-456b-f818-9418a11b316c"
      },
      "source": [
        "## DataLoader (Load the training set and validation set using Dataset and DataLoader)\n",
        "transform = torchvision.transforms.ToTensor()\n",
        "train_data = torch.utils.data.DataLoader(\n",
        "    torchvision.datasets.MNIST(\n",
        "    'mnist_data', train=True, download=True, transform=transform\n",
        "    ), batch_size=batch_size\n",
        ")\n",
        "val_data = torch.utils.data.DataLoader(\n",
        "    torchvision.datasets.MNIST(\n",
        "    'mnist_data', train=False, download=True, transform=transform\n",
        "    ), batch_size=batch_size\n",
        ")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ea9v0rBFtWAj"
      },
      "source": [
        "# Validation function (To check whether the model is learning properly we can use a validation set)\n",
        "def validate(model, data):\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for i, (images, labels) in enumerate(data):\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        y_pred = model(images)\n",
        "        value, pred = torch.max(y_pred, 1)\n",
        "        total += y_pred.size(0)\n",
        "        correct += torch.sum(pred == labels)\n",
        "    return correct * 100 / total\n",
        "    "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Uc9ybejtWCY"
      },
      "source": [
        "## Training Function (Training the model)\n",
        "def train(model,epochs=5) :\n",
        "    optimizer = optim.Adam(model.parameters(),lr=learning_rate)    \n",
        "    for n in range(epochs)  :\n",
        "        for i , (images , labels) in enumerate(train_data) :\n",
        "            images = images.cuda()\n",
        "            labels = labels.cuda()\n",
        "            optimizer.zero_grad()\n",
        "            prediction = model(images)\n",
        "            loss = cross_entropy(prediction, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        accuracy = float(validate(model, val_data))\n",
        "        print(\"Epoch:\", n+1, \"Loss: \", float(loss.data), \"Accuracy:\", accuracy)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90WCj3fbtWEb"
      },
      "source": [
        "## Model (Define Model)\n",
        "class ANN(nn.Module) :\n",
        "    def __init__(self):\n",
        "        super(ANN,self).__init__()\n",
        "        self.dense_1 = nn.Linear(in_features=784,out_features=256)\n",
        "        self.dense_2 = nn.Linear(in_features=256,out_features=10)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "    def forward(self,x) :\n",
        "        x = x.view(x.shape[0],-1)\n",
        "        x = self.relu(self.dense_1(x))\n",
        "        x = self.dense_2(x)\n",
        "        # output = self.tanh(x)\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "\n",
        "        return output"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYRgTkK2tWGi"
      },
      "source": [
        "# Model (Model instance)\n",
        "model = ANN().cuda()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6jbvgbAtWJP",
        "outputId": "8cb1dddc-b198-4d32-a3ce-7993ccaa0a77"
      },
      "source": [
        "# Summary\n",
        "summary(model, (1, 28, 28))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                  [-1, 256]         200,960\n",
            "              ReLU-2                  [-1, 256]               0\n",
            "            Linear-3                   [-1, 10]           2,570\n",
            "================================================================\n",
            "Total params: 203,530\n",
            "Trainable params: 203,530\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.78\n",
            "Estimated Total Size (MB): 0.78\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1lgF6e7uJFg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc60b7a8-50d3-48cd-dc42-f63d92f8f4ad"
      },
      "source": [
        "# Train for 30 Epochs\n",
        "train(model,epochs=30)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 Loss:  0.018450777977705002 Accuracy: 94.55999755859375\n",
            "Epoch: 2 Loss:  0.04523979872465134 Accuracy: 96.05999755859375\n",
            "Epoch: 3 Loss:  0.004567528143525124 Accuracy: 95.05999755859375\n",
            "Epoch: 4 Loss:  0.0027272189036011696 Accuracy: 95.82999420166016\n",
            "Epoch: 5 Loss:  6.891608791192994e-05 Accuracy: 96.30999755859375\n",
            "Epoch: 6 Loss:  0.03125550597906113 Accuracy: 92.80999755859375\n",
            "Epoch: 7 Loss:  0.00023395652533508837 Accuracy: 95.95999908447266\n",
            "Epoch: 8 Loss:  0.00023131839407142252 Accuracy: 96.44999694824219\n",
            "Epoch: 9 Loss:  9.077379218069836e-06 Accuracy: 96.22999572753906\n",
            "Epoch: 10 Loss:  0.006186465732753277 Accuracy: 96.02999877929688\n",
            "Epoch: 11 Loss:  0.0006802300340496004 Accuracy: 96.94999694824219\n",
            "Epoch: 12 Loss:  4.100344449398108e-05 Accuracy: 96.83999633789062\n",
            "Epoch: 13 Loss:  2.2935677407076582e-05 Accuracy: 96.25999450683594\n",
            "Epoch: 14 Loss:  3.574645234039053e-05 Accuracy: 96.86000061035156\n",
            "Epoch: 15 Loss:  0.0023283963091671467 Accuracy: 96.5199966430664\n",
            "Epoch: 16 Loss:  2.3431227873516036e-06 Accuracy: 96.6199951171875\n",
            "Epoch: 17 Loss:  0.003291554981842637 Accuracy: 96.90999603271484\n",
            "Epoch: 18 Loss:  0.04053990915417671 Accuracy: 96.75999450683594\n",
            "Epoch: 19 Loss:  0.033872202038764954 Accuracy: 96.77999877929688\n",
            "Epoch: 20 Loss:  0.00013816410501021892 Accuracy: 97.0999984741211\n",
            "Epoch: 21 Loss:  1.8028928025159985e-05 Accuracy: 97.08999633789062\n",
            "Epoch: 22 Loss:  1.5087225619936362e-06 Accuracy: 96.93000030517578\n",
            "Epoch: 23 Loss:  0.025565076619386673 Accuracy: 97.08999633789062\n",
            "Epoch: 24 Loss:  8.693155541550368e-05 Accuracy: 97.08999633789062\n",
            "Epoch: 25 Loss:  0.0 Accuracy: 96.94999694824219\n",
            "Epoch: 26 Loss:  0.0 Accuracy: 97.0999984741211\n",
            "Epoch: 27 Loss:  0.0 Accuracy: 97.14999389648438\n",
            "Epoch: 28 Loss:  2.607702498380604e-08 Accuracy: 96.88999938964844\n",
            "Epoch: 29 Loss:  3.725290076417309e-09 Accuracy: 97.29000091552734\n",
            "Epoch: 30 Loss:  0.0 Accuracy: 96.90999603271484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUS-wn-vDamN"
      },
      "source": [
        "**We can see that there are less parameters here, and the training is significantly quicker. Even after achieving zero, we can see that the loss fluctuates. Because it does not capture spatial information, the accuracy of a Normal Neural Network should be lower than that of a Convolution Neural Network. Because there are no complex characteristics to learn for the MNIST dataset, we can observe that the model achieves reasonable accuracy.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvYvNqVmuJII"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    }
  ]
}